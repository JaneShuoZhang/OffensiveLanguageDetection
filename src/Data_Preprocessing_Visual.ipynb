{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordsegment import load, segment\n",
    "import emoji\n",
    "from preprocessing import process_single_tweet, process_train_data, process_test_data\n",
    "from utils import load_train_data, load_test_data_a\n",
    "from feature_embedding import get_all_character_ngrams_of_sentence, build_ngrams_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data: 13240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet subtask_a\n",
       "0  @USER She should ask a few native Americans wh...       OFF\n",
       "1  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF\n",
       "2  Amazon is investigating Chinese employees who ...       NOT\n",
       "3  @USER Someone should'veTaken\" this piece of sh...       OFF\n",
       "4  @USER @USER Obama wanted liberals &amp; illega...       NOT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = load_train_data()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from NLTK twitter tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL\n",
      "['@USER', '@USER', 'Go', 'home', 'you', 'â€™', 're', 'drunk', '!', '!', '!', '@USER', '#MAGA', '#Trump2020', 'ðŸ‘Š', 'ðŸ‡º', 'ðŸ‡¸', 'ðŸ‘Š', 'URL']\n"
     ]
    }
   ],
   "source": [
    "example = train_data[\"tweet\"][1]\n",
    "print(example)\n",
    "twt_tokenizer = TweetTokenizer()\n",
    "tokenized = twt_tokenizer.tokenize(example)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from our tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@USER @USER Go home youâ€™re drunk!!! @USER #MAGA #Trump2020 ðŸ‘ŠðŸ‡ºðŸ‡¸ðŸ‘Š URL\n",
      "go home you are drunk ! ! ! maga trump 2020 oncoming fist united states oncoming fist\n"
     ]
    }
   ],
   "source": [
    "print(example)\n",
    "print(process_single_tweet(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of test data A: 860\n",
      "Processed data already exists. Direct load it.\n",
      "number of processed data: 860\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who is q wheres the server dump nike dec las f...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>constitution day is revered by conservatives h...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foxnews nra maga potus trump 2nd amendment rnc...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watching boomer getting the news that she is s...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no pasaran unity demo to oppose the far right ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet subtask_a\n",
       "0  who is q wheres the server dump nike dec las f...       OFF\n",
       "1  constitution day is revered by conservatives h...       NOT\n",
       "2  foxnews nra maga potus trump 2nd amendment rnc...       NOT\n",
       "3  watching boomer getting the news that she is s...       NOT\n",
       "4  no pasaran unity demo to oppose the far right ...       OFF"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = load_test_data_a()\n",
    "test_data = process_test_data(test_data)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Character n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhhhh so funny !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'!': 1,\n",
       " 'f': 1,\n",
       " 'fu': 1,\n",
       " 'fun': 1,\n",
       " 'funn': 1,\n",
       " 'h': 5,\n",
       " 'hh': 4,\n",
       " 'hhh': 3,\n",
       " 'hhhh': 2,\n",
       " 'n': 2,\n",
       " 'nn': 1,\n",
       " 'nny': 1,\n",
       " 'ny': 1,\n",
       " 'o': 1,\n",
       " 's': 1,\n",
       " 'so': 1,\n",
       " 'u': 1,\n",
       " 'un': 1,\n",
       " 'unn': 1,\n",
       " 'unny': 1,\n",
       " 'y': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"hhhhh so funny !\"\n",
    "print(example)\n",
    "get_all_character_ngrams_of_sentence(example)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build training data based on character n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "Shape of X is (10, 976)\n",
      "[1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "sample_train = test_data.head(10)\n",
    "sample_test = test_data.tail(5)\n",
    "train_set = build_ngrams_dataset(sample_train)\n",
    "print(train_set['X'])\n",
    "print(\"Shape of X is {}\".format(train_set['X'].shape))\n",
    "print(train_set['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build test data using the same vectorizer when building training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 2. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [0. 1. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = train_set['vectorizer']\n",
    "test_set = build_ngrams_dataset(sample_test, vectorizer=vectorizer)\n",
    "print(test_set['X'])\n",
    "print(test_set['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
